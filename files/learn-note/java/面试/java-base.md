#### comparator和comparable
两者都是用来实现集合中元素的比较、排序的，只是comparable是在集合内部定义的方法实现的排序，comparator是在集合外部实现的排序。所以，若想实现排序，就需要在集合外定义Comparator接口的方法或者在集合内部实现comparable接口的方法。  
comparator位于包java.util下，comparable位于包java.lang下。  
Comparable是一个对象本身就已经支持自比较所需要实现的接口（如string integer自身可以比较大小，已经实现了Comparable接口），自定义的类要在加入list容器后能够排序，可以实现comparable接口，在用Collections.sort方法排序时，如果不指定comparator那么就以自然顺序排序，自然顺序即实现comparable接口设定的排序方式。  
Comparator是一个专用的比较器，当这个对象不支持自比较或者自比较函数无法满足需求时，可以写一个比较器完成两个对象之间大小的比较。  
使用comparator是策略模式，就是不改变对象自身，而用一个策略对象来改变它的行为。
#### 动态代理
在程序运行期间，为其他对象提供一个代理以控制对某个对象的访问，代理类负责为委托类预处理消息，过滤消息并转发消息，以及进行消息被委托类执行后的后续处理。
##### JDK动态代理
只针对接口做代理，依赖Proxy类和InvocationHandler接口。由Java内部的反射机制来实现的。
* InvocationHandler接口的方法：invoke(Object obj,Method method, Object[] args)，第一个参数一般是指代理类，method是被代理的方法，args为该方法的参数数组。
* Proxy：动态代理类，getProxyClass（获得一个代理类）、newProxyInstance（返回代理类的一个实例）
> 当代理对象调用真实对象的方法时，其会自动的跳转到代理对象关联的handler对象的invoke方法来进行调用。JDK生成的最终代理类继承自Proxy并实现了自定义的被代理的类接口，在实现接口方法的内部，通过反射调用了InvocationHandlerImpl的invoke方法。
###### 动态代理步骤
1. 创建一个实现接口InvocationHandler的类，它必须实现invoke方法 （创建自己的调用处理器）；
2. 创建被代理的类及接口；
3. 通过Proxy的静态方法newProxyInstance(ClassLoaderloader, Class[] interfaces, InvocationHandler h)创建一个代理；
4. 通过代理调用方法 （通过反射机制获得动态代理类的构造函数，其唯一参数类型是调用处理器接口类型、通过构造函数创建动态代理类实例，构造时调用处理器对象作为参数被传入）；
##### cglib动态代理
可以对任意类生成代理对象，它的原理是对目标对象进行继承代理，如果目标对象被final修饰，那么该类无法被cglib代理。  
需要导入asm.jar
###### 实现步骤
1. 创建一个实现接口MethodInterceptor的代理类，重写intercept方法；
2. 创建获取被代理类的方法getInstance(Object target)；
3. 获取代理类，通过代理调用方法。
#### 类实例化顺序
父类静态代码块/静态域 > 子类静态代码块/静态域 > 父类非静态代码块 > 父类构造器 > 子类非静态代码块 > 子类构造器
#### 创建java对象的方式
* new语句；
* 反射，使用Class.newInstance()创建/调用类对象的构造方法--Constructor；
* 调用对象的clone()方法；
* 运用反序列化手段，调用java.io.ObjectInputStream对象的readObject()方法；
* 使用Unsafe。
#### Atomic原子类
Atomic指一个操作是不可中断的。即使是在多线程一起执行，一个操作一旦开始，就不会被其他线程干扰。所谓原子类就是具有原子特性的类。并发包 java.util.concurrent 的原⼦类都存放在 java.util.concurrent.atomic
#### synchronized实现原理及锁优化
* synchronized作用于方法或代码块，保证被修饰的代码在有同一时间只能被一个线程访问；
* 修饰代码块时，jvm采用monitorenter、monitorexit两个指令来实现同步；
* 修饰同步方法时，jvm采用ACC_SYNCHRONIZED标记符来实现同步；
* monitorenter、monitorexit、ACC_SYNCHRONIZED都是基于Monitor实现的；
* 实例对象里有对象头，对象头里面有Mark Word，Mark Word指针指向了monitor；
* Monitor其实是一种同步工具，也可以说是一种同步机制；
* 在java虚拟机中，Monitor是由ObjectMonitor实现的。
> _count：记录线程获取锁的次数；_recursion：锁的重入次数；_owner：指向持有ObjectMonitor对象的线程；_WaitSet：处于wait状态的线程会被加入进来；_EntryList：处于等待锁block状态的线程会被加入到该列表。
##### 锁优化
Java对象头Mark Word结构：存储对象自身的运行数据，如哈希码、GC分代年龄、锁状态标志、偏向时间戳等；以及区分优化了不同的锁：
> 1.6之前synchronized实现世界调用enter和exit，这种被称为重量级锁。1.6之后对锁进行了优化，增加了适应性自旋、锁消除、锁粗化、轻量级锁和偏向锁。
* 偏向锁：无竞争情况下，把整个同步都消除掉，CAS操作都不做；
* 轻量级锁：在没有多线程竞争时，相对重量级锁减少操作系统互斥量带来的性能消耗，但是如果存在锁竞争，除了互斥量开销还有额外CAS操作开销；
* 自旋锁：减少不必要的CPU上下文切换，在轻量级锁升为重量级锁时就使用了自旋加锁的方式；
* 锁粗化：将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁；
* 锁消除：虚拟机即时编译器在运行时，对一些代码上要求同步但是被检测到不可能存在共享数据竞争的锁进行消除。
#### ThreadLocal
Thread类有一个类型为ThreadLocal.ThreadLocalMap的实例变量threadLocals，即每个线程都有一个属于自己的ThreadLocalMap.  
ThreadLocalMap内部维护着Entry数组，每个entry代表一个完整的对象，key是ThreadLocal本身，value是ThreadLocal的泛型值。  
每个线程在往ThreadLocal里设值的时候，都是往自己的ThreadLocalMap里存，读也是以某个ThreadLocal作为引用，在自己的map里找到对应的key，从而实现了线程隔离。
##### 内存泄露问题
> ThreadLocalMap使用的key为ThreadLocal的弱引用，只要垃圾一回收，不管jvm空间是否充足，都会回收该对象占用的内存。

弱引用比较容易被回收，所以，如果ThreadLocal（ThreadLocalMap中的key）被回收了，但是因为ThreadLocalMap的生命周期和Thread是一样的，它此时不被回收的话，就会出现：ThreadLocalMap的key没了，value还在，这就会造成内存泄露。  
因此，使用完ThreadLocal后，即时调用remove()方法释放内存空间。
> 应用场景：数据库连接池 会话管理
#### 栈溢出
* 栈是线程私有的，他的生命周期与线程相同，每个方法在执行的时候都会创建一个栈帧，用来存放局部变量表，操作数栈，动态链接，方法出口等信息。局部变量表又包含基本数据类型、对象引用类型；
* 如果线程请求的栈深度大于虚拟机允许的最大深度，将抛出StackOverflowError异常，方法递归调用经常产生这种结果；
* 如果Java虚拟机栈可动态扩展，并且扩展动作已尝试过，但是无法申请到足够内存去完成扩展，或者在新建立线程的时候没有足够的内存去创建对应的虚拟机栈，那么虚拟机将抛出OutOfMemory异常（一般是线程启动过多）；
* 参数-Xss可以调整jvm栈大小。
#### jvm分代，新生代分Eden、Survivor
内存区划分
* 共享内存区=持久代+堆；
* 持久代=方法区+其他；
* Java堆=老年代+新生代；
* 新生代=Eden+S0+S1
##### 参数配置
* 默认，新生代与老年代比例1:2，可通过参数-XX:NewRatio配置；
* 默认，Eden:form:to = 8:1:1，可以通过参数 –XX:SurvivorRatio设置；
* Survivor区中的对象被复制的次数为15，虚拟机参数-XX:+MaxTenuringThreshold。
##### 新生代分区
* 如果没有Survivor，Eden区每进行一次Minor GC，存活的对象就被送到老年代。老年代很快被填满，触发Major GC。老年代内存空间远大于新生代，进行一次full GC消耗时长远多于minor GC，所以需要分为Eden和Survivor；
* Survivor存在的意义就是减少被送到老年代的对象进而减少full GC发生；
* Survivor的预筛选保证，只有经历16次minor GC还能在新生代存活的对象才会被送到老年代；
* 设置两个Survivor最大的好处是解决了碎片化，刚刚新建的对象在Eden中，经历一次minor GC，Eden中的存活对象就会被移动到第一块Survivor space S0，Eden被清空；等Eden再满了，就再触发一次minor GC，Eden和S0中存活的对象又会被复制送入到第二块Survivor space S1（此过程很重要，因为复制算法保证了S1中来自S0和Eden两个部分的存活对象占用连续的内存空间，避免碎片化）。
#### jvm中GC的流程
* Java 堆：老年代+新生代；
* 新生代：Eden+S0+S1；
* 当Eden空间满了，Java虚拟机会触发一次minor GC，以收集新生代的垃圾，存活下来的对象则会转移到Survivor区；
* 大对象（需要大量连续内存空间的Java对象，如很长的字符串）直接进入老年代，；
* 如果对象在Eden出生，并经过一次minor GC后仍存活，并且被Survivor容纳，年龄设为1，每经历过一次minor GC，年龄+1，直到超过15，则晋升到老年代，即长期存活的对象进入老年代；
* 老年代填满无法容纳更多对象，minor GC之后通常就会进行full GC，full GC清理整个内存堆，包括年轻代和老年代；
* major GC发生在老年代，经常会伴随至少一次minor GC，比minor GC慢10倍以上。
#### 主要的jvm参数
* -Xmx3550m：最大堆大小3550m
* -Xms3550m：设置初始堆大小3550m
* -Xmn2g：设置年轻代大小2g
* -Xss128k：每个线程堆栈大小128k
* -XX:MaxPermSize：设置持久代大小
* -XX:NewRatio=4：设置年轻代与老年代比值
* -XX:+UseParallelGC：选择垃圾收集器为并行收集器
* -XX:ParallelGCThreads=20：配置并行收集器线程数
* -XX:+UseConcMarkSweepGC：设置老年代为并发收集
#### 查询堆栈信息
* jps 进程号；
* top -Hp pid 获取本进程中所有线程的 CPU 耗时性能
* jstack pid 命令查看当前 java 进程的堆栈状态
* jstack -l > /tmp/output.txt 把堆栈信息打到一个 txt 文件
#### 常见调优策略
* 选择合适的垃圾回收器；
* 调整内存大小（垃圾收集频率非常频繁，如果内存太小可调大内存）；
* 调整内存区域大小比例（某一个区域GC频繁，其他区正常）；
* 调整对象晋升老年代的年龄（老年代频繁的GC，每次回收的对象很多）；
* 调整大对象的标准（老年代频繁GC，每次回收的对象很多并且单个对象体积都比较大）；
* 调正GC的触发时机（CMS，G1经常Full GC，程序卡顿严重）；
* 调整JVM本地内存大小（GC的次数，时间和回收的对象都正常，堆内存空间充足，但是报OOM）。
#### 类加载器和双亲委派
##### 类加载器
根据指定全限定名称将class文件加载到jvm内存，转为class对象
* 启动类加载器（Bootstrap ClassLoader）：由C++实现，负责将存放在lib目录下的类库加载到内存中；
* 其他类加载器：由Java实现，继承自抽象类ClassLoader；如：
* 扩展类加载器（Bootstrap ClassLoader）：java.ext.dirs 系统变量指定的路径中的所有类库；
* 应用程序类加载器（Application ClassLoader）：负责加载用户类路径上的指定类库，可以直接只用这个类加载器。默认类加载器
##### 双亲委派
> 如果一个类加载器收到类加载请求，它首先不会自己去尝试加载这个类，而是把请求委派给父类加载器完成。每个类加载器都如此，只有当父类加载器在自己的搜索范围内找不到指定的类时，子加载器才会尝试自己去加载。

为什么：
> 如果没有双亲委派，那么用户就可以自定义一个Object同名类，并把它放到class path中，那么类之间的比较结果以及类的唯一性将无法保证。主要是为了防止内存中出现多份同样的字节码。

打破双亲委派机制不仅要继承classLoader类，还要重写loadclass和findclass方法。
#### 四种引用
* 强引用：如new对象产生的引用，即在内存不足的情况下，jvm宁可抛出outofmemory错误也不会回收此类对象；
* 软引用：如果一个对象只具有软引用，则内存空间足够，垃圾回收器就不会进行回收，若内存空间不足就会回收这些对象的内存；例如浏览器的回退按钮，显示的网页内容是重新进行请求还是从缓存中取出；
* 弱引用：具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存；
* 虚引用：如果一个对象仅持有虚引用，那么它和没有任何引用一样，在任何时候都可能被垃圾回收。虚引用主要是用来跟踪对象被垃圾回收器回收的活动。
#### nacos选举机制
nacos作为配置中心的功能是基于raft算法来实现的。涉及三种角色和任期（term）
* follower：接受和处理来自leader的信息，当等待leader心跳信息超时时，则会主动推荐自己担当Candidate；
* Candidate：向其他节点发送投票请求，通知其他节点投票，若得到大多数票(n/2+1)，则晋升为leader；
* leader：负责处理客户端请求，进行日志复制等操作，每一轮选举的目标就是选出一个领导者，领导者会不断发送心跳信息通知其他节点；
* term：每一次leader领导时间  
##### 选举过程
* 初始时，集群中所有节点都是follower状态，都被设定一个随机选举超时时间（一般150ms-300ms）；
* 如果follower在规定的超时时间都没有收到来自leader的心跳，它就发起选举，将自己状态切换为Candidate，增加自己的任期编号，然后向集群中其他的follower节点发送请求，询问是否可以选举自己成为leader；
* 其他节点收到候选人A的请求，如果在编号1任期内还未投过票，那么它将把票投给节点A，并增加自己的任期编号；
* 当收到集群中过半节点的接受投票后，A节点即成为本届任期内的leader，它将周期性的发送心跳消息，通知其他节点我是leader，组织follower发起新选举；
#### MySQL索引结构 聚簇索引和非聚簇索引
* 一个表只能有一个聚集索引，而非聚集索引一个表可以存在多个；
* 索引是通过二叉树的数据结构来描述的，聚簇索引：索引的叶节点就是数据节点；非聚簇索引：叶节点仍然是索引节点，只不过有一个指针指向对应的数据块。
* 聚簇索引：物理存储按照索引排序；非聚簇索引：物理存储不按索引排序。
#### MySQL索引失效
* 查询条件包含or，可能导致索引失效；
* 如果字段类型是字符串，where时一定要用引号，否则索引失效；
* 在索引列上使用MySQL内置函数；
* like通配符可能导致索引失效；
* 联合索引，查询时的条件列不是联合索引中的第一个列，索引失效；
* 对索引列运算；
* 索引字段上使用（!= 或者<>,not in），可能会导致失效；
* 索引字段上使用is null，is not null；
* 左连接查询或者右连接查询查询关联的字段编码格式不一致；
#### HashMap
JDK1.7底层数据结构是数组+链表，JDK1.8底层数据结构是数组+链表+红黑树。  
数据元素通过映射关系，即散列函数，映射到桶数组对应的索引位置，插入该位置时，如果发生冲突，从冲突的位置拉一个链表，把冲突元素放到链表。如果链表的长度>8且数组大小>=64，链表转为红黑树，如果红黑树节点个数<6，转为链表。
##### 为什么用红黑树，不用二叉树、平衡二叉树
红黑树是一种平衡的二叉树，其插入、删除和查找的最坏时间复杂度都为O(logn)，避免了二叉树最坏情况下的O(n)时间复杂度；  
平衡二叉树是比红黑树更严格的平衡树，为了保持平衡，需要旋转的次数更多，也就是说平衡二叉树保持平衡的效率更低，所以平衡二叉树插入和删除的效率比红黑树低。
##### 为什么链表大于8时会转红黑树
红黑树的平均查找长度是log(n)，如果长度为8，平均查找长度log(8)=3，链表的平均查找长度为n/2，当长度为8时，平均查找长度=4，这才有转红黑树的必要；链表长度如果小于等于6，6/2=3，而log(6)=2.6，虽然速度也会很快，但是转化为树结构和生成树时间并不短。

#### http和https
HTTP即超文本传输协议，是一个基于TCP/IP通信协议来传递明文数据的协议。请求信息是明文传输容易被窃听截取；没有验证对方身份，存在被冒充风险；数据的完整性未校验，容易被中间人篡改。  
HTTPS=HTTP+SSL/TLS，可以理解为身披SSL-安全套接层的HTTP。
* HTTP不安全，HTTPS安全；
* HTTP默认80端口，HTTPS默认443端口；
* HTTP消耗资源较少，HTTPS消耗资源较多；
* HTTP不需要证书，HTTPS需要证书；
* HTTP报文不加密，HTTPS报文加密。
##### https原理
* 客户端发起HTTPS请求，连接到服务器的443端口；
* 服务器必须要有一套数字证书(证书内容有公钥、证书颁发机构、失效日期等)；
* 服务器将自己的数字证书发送给客户端(公钥在证书里，私钥由服务器持有)；
* 客户端收到数字证书后，验证证书合法性，如果证书验证通过，就会生成一个随机的对称密钥，用证书的公钥加密；
* 客户端将公钥加密后的密钥发送给服务器；
* 服务器收到客户端发送来的密文密钥后，用自己之前保留的私钥对其进行非对称解密，解密之后就得到客户端的密钥，然后由客户端密钥对返回数据进行对称加密；
* 服务器将加密后的密文返回客户端；
* 客户端收到后，用自己的密钥对其进行对称解密，得到服务器返回的数据。
##### HTTP请求头里字段含义
* cache-control：是HTTP/1.1的头字段，用来区分对缓存机制的支持情况，请求头和响应头都支持这个属性。通过它提供的值来定义缓存策略（public private no-cache）；
* expires：HTTP1.0的头字段，过期时间，如果设置了过期时间则浏览器会在设置的过期时间内存直接读取缓存不会再请求。
##### 常见HTTP状态码
* 101：切换请求协议
* 200：成功
* 301：永久重定向，会缓存
* 302：临时重定向，不会缓存
* 400：客户端请求语法错误；
* 403：服务器禁止访问，权限有关；
* 404：服务端无法根据客户端请求找到资源；
* 500：服务端错误。
#### 数据库高可用
高可用，即high availability，是分布式系统架构设计必须要考虑的因素之一，通常是指通过设计减少系统不能提供服务的时间。单机部署谈不上高可用，因为单点故障问题。高可用是多个节点的，我们在考虑MySQL数据库的高可用时需考虑几个方面：
* 如果数据库节点宕机，需要尽快恢复，保证业务不受宕机影响；
* 从数据库节点的数据，尽可能跟主节点数据保持实时一致性，至少保证最终一致性；
* 数据库节点切换时，数据不能丢失。
##### 主从或主主半同步复制
用双节点数据库，搭建单向或者双向的半同步复制。通常会和proxy、keepalived等第三方软件同时使用，既可以用来监控数据库的健康，又可以执行一系列管理命令。如果主库发生故障，切换到备库后仍然可以使用数据库。  
这种方案优点是架构、部署比较简单，主机宕机可以直接切换。缺点是完全依赖于半同步复制，半同步复制退化为异步复制，无法保证数据一致性；另外还需要额外考虑haproxy、keepalived的高可用机制。
##### 半同步复制优化
半同步复制是可靠的，可以保证数据一致性。但是网络发生波动，半同步复制发生超时会切换为异步复制，异步复制无法保证数据一致性。因此，可以优化下半同步复制，尽可能保证半同步复制。如双通道复制方案：
* 优点是架构、部署也比较简单，主机宕机直接切换即可，比起半同步复制更能保证数据一致性；
* 需要修改内核源码或者使用MySQL通信协议，未从根本上解决数据一致性问题。
##### 高可用架构优化
保证高可用，可以把主从双节点数据库扩展为数据库集群。zookeeper可以作为集群管理，它使用分布式算法保证集群数据一致性，可以较好避免网络分区现象产生。
* 优点：保证了整个系统的高可用性，扩展性也较好，可以扩展为大规模集群；
* 缺点：数据一致性仍然依赖于原生MySQL半同步复制，且引入zookeeper让系统更复杂。
##### 共享存储
共享存储实现了数据库服务器和存储设备的解耦，不同数据库之间的数据同步不再依赖于MySQL的原生复制功能，而是通过磁盘数据同步的手段，来保证数据一致性。  
DRBD复制：一个用软件实现的、无共享的、服务器之间镜像块设备内容的存储复制解决方案。主要用于对服务器之间的磁盘、分区、逻辑卷等进行数据镜像，当用户将数据写入本地磁盘时，还是将数据发送到网络上另一台主机的磁盘上，这样本地主机（主节点）与远程设备（从节点）的数据就可以保证实时同步。当本地主机出现问题时，远程主机还保存着一份相同的数据，即可以继续使用，保证了数据的安全。
* 优点：部署简单，价格合适，保证数据的强一致性；
* 缺点：对IO性能影响较大，从库不提供读操作。
##### 分布式协议
分布式协议可以很好的解决数据一致性问题。常见的部署方案就是MySQL cluster，它是官方集群的部署方案，通过使用NDB存储引擎实时备份冗余数据，实现数据高可用和一致性。
* 优点：不依赖于第三方软件，可以实现数据库的强一致性；
* 缺点：配置比较复杂，需要使用NDB存储引擎，至少三节点。
#### 读写分离，如何保证从数据库读到最新数据
数据库读写分离，主要解决高并发时，提高系统的吞吐量。
* 写请求是直接写主库，然后同步数据到从库；
* 读请求一般是直接读从库，除非强制读主库。
在高并发场景或网络不佳的场景，如果存在较大的主从同步数据延迟，这时候读请求去读从库，就会读到旧数据。最简单暴力的方法是强制读主库。实际可以使用缓存标记法：
* A发起写请求，更新主库数据，并在缓存中设置一个标记，表示数据已更新；
* 设置此标记，设置过期时间（估值为主库和从库之间同步延迟的时间）；
* B发起读请求，先判断此请求在缓存中有没有标记；
* 如果存在标记走主库，如果没有读从库。

这个方案解决了数据不一致的问题，但是每次请求都要先处理缓存，影响系统吞吐。
#### 如何保证MySQL数据不丢 
MySQL这种关系型数据库，是日志先行策略（write-ahead loading），只要binlog和redo log日志能保证持久化到磁盘，我们就能确保MySQL异常重启后数据也不丢失。
##### binlog日志
binlog又称为二进制日志，它会记录数据库执行更改的所有操作，但是不包括查询select等操作。一般用于恢复、复制等功能。有三种格式：statement、mixed、row
* statement：每一条会修改数据的SQL都会记录到binlog中，不建议使用；
* row：基于行的变更情况记录，会记录行更改前后的内容；
* mixed：混合前两种模式；

binlog的写入机制，事务执行过程中先把日志写道binlog cache，事务提交的时候，再把binlog cache写到binlog文件。  
系统为每个客户端线程分配一个binlog cache，其大小值控制参数是binlog_cache_size。如果binlog cache值超过阈值，就会临时持久化到磁盘。当事务提交时再将binlog cache中完整的事务持久化到磁盘中，并且清空binlog cache。  
binlog写文件，分write和fsync两个过程：
* write：指把日志写到文件系统的page cache，并没有把数据持久化到磁盘，因此速度较快；
* fsync：实际的写盘操作，即把数据持久化到磁盘。
> write和fsync的写入时机是由变量sync_binlog控制的，sync_binlog=0：表示每次提交事务都只write，不fsync；sync_binlog=1表示每次提交事务都会fsync；sync_binlog=N(N>1)表示每次提交事务都write，但累计N个事务后才fsync。如果IO出现性能瓶颈，可以将sync_binlog设置为一个较大的值。比如设置为（100-1000）.但是会存在数据丢失风险，当主机异常重启时，会丢失N个最近提交的事务binlog。
##### redo log日志
redo log日志又称为重做日志文件，只记录事务对数据页做了哪些修改，它记录的是数据修改之后的值。redo有三种状态：
* 物理上是在MySQL进程内存中，存在redo log buffer中；
* 物理上是在文件系统的page cache里，写到磁盘(write)但是还没有持久化（fsync）；
* 存在hard disk已经持久化到磁盘。

日志写到redo log buffer是很快的，write到page cache也很快，但是持久化到磁盘比较慢。  
为了控制redo log的写入策略，Innodb根据innodb_flush_log_at_trx_commit参数不同的取值采用不同的策略，它有三种不同的取值：
* 0：表示每次事务提交都只是把redo log留在redo log buffer中；
* 1：表示每次事务提交都将redo log直接持久化到磁盘；
* 2：表示每次事务提交都只是把redo log写到page cache。
> 三种模式下，设置为0的性能最好，但是不安全，MySQL进程一旦崩溃会导致丢失一秒的数据；设置为1的安全性最高，但是对性能影响最大；设置为2的话，主要由操作系统自行控制刷盘时间，如果仅仅是MySQL宕机，对数据不会产生影响，如果是主机异常宕机了，同样会丢失数据。
#### 高并发下的秒杀系统设计
秒杀系统可能存在的问题：高并发，瞬间用户请求极大、黄牛黑客恶意请求、链接暴露的问题、数据库抗压问题、库存不足和超卖问题。解决方案：
* 页面静态化
* 按钮置灰控制
* 服务单一职责
* 秒杀链接加盐
* 限流
* 分布式锁
* MQ异步处理
* 限流、降级、熔断
##### 页面静态化
秒杀活动的页面大多数内容是固定不变的，如商品名称、图片等，可以对活动页面做静态化处理，减少对服务端的请求。可以使用CDN内容分发网络让用户就近获取所需内容。
##### 按钮置灰控制
活动开始前，按钮置灰，到时间才可点击。
##### 服务单一职责
依据微服务设计思想，把各个功能模块拆分，再用分布式方式部署。服务单一职责好处是若因为高并发压力秒杀系统库崩了，服务挂了，但也不会影响到系统的其他服务。
##### 秒杀链接加盐
链接如果直接明文暴露的话，会有人提前获取到url提前秒杀。所以需要给链接加盐，URL动态化，如通过MD5加密算法加密随机字符串做url。
##### 限流
一般两种方式限流：nginx限流和redis限流
* 为了防止某个用户请求过去频繁，可以对同一用户限流；
* 可以对某个IP进行限流；
* 防止有人使用代理每次都更换IP请求，可以对接口进行限流；
* 为了防止瞬时过大的流量压垮系统，可以使用阿里sentinel、hystrix组件进行限流。
##### 分布式锁
可以使用分布式锁解决超卖问题。使用redis的set ex px nx + 校验唯一随机值，再删除释放锁。使用lua脚本判断是不是当前线程加的锁和释放锁不是一个原子操作。
##### MQ异步处理
如果瞬间流量很大，使用消息队列削峰，异步处理。用户请求过来先放入消息队列，再拿出来消费。
#### 对称与非对称加密算法
* 明文：指没有加密过的信息/数据；
* 密文：明文被加密后；
* 密钥：一种参数，是在明文被转换为密文或将密文转换为明文时算法中输入的参数。密钥分对称和非对称密钥
* 加密：将明文变成密文的过程；
* 解密：将密文还原为明文的过程。

对称加密算法：加密和解密使用相同密钥的加密算法，常见对称加密算法有：AES、3DES、DES、RC5、RC6等。  
非对称加密算法：需要两个密钥（公钥和私钥），公钥和私钥是成对存在的，如果用公钥对数据加密，只有对应的私钥才能解密。常见的算法有：RSA、Elgamal、DSA、D-H、ECC。
#### TCP如何保证可靠性
* TCP链接基于三次握手，断开则是四次挥手，确保链接和断开的可靠性；
* TCP有状态，TCP会记录哪些数据发送了，哪些数据被接受了，哪些没有被接受，并且保证数据包按序到达，保证数据传输不出错；
* TCP可控制，有报文检验、ACK应答、超时重传、失序数据重传、丢弃重复数据、流量控制、和拥塞控制等机制。
#### 五种IO模型
##### 阻塞IO模型
假设应用程序的进程发起IO调用，但是如果内核的数据还没有准备好的话，那应用程序就一直在阻塞等待，一直到内核数据准备好了，从内核拷贝到用户空间，才返回成功提示，此次IO操作称之为阻塞IO。
##### 非阻塞IO模型
如果内核数据还没准备好，可以先返回错误信息给用户进程，让它不需要等待，而是通过轮询的方式再来请求，就是非阻塞IO。
##### IO多路复用模型
IO多路复用之select：应用进程通过调用select函数，可以同时监控多个fd，在select函数监控的fd中，只要有任何一个数据状态准备就绪了，select函数就会返回可读状态，这时应用进程再发起recvfrom请求去读数据。但是select最大连接数有限，在Linux系统上一般为1024；select函数返回后是通过遍历fdset，找到就绪的描述符fd。
IO多路复用之epoll：采用事件驱动来实现，epoll先通过epoll_ctl()来注册一个fd(文件描述符)，一旦基于某个fd就绪时，内核会采用回调机制，迅速激活这个fd，当进程调用epoll_wait()时便得到通知。这里去掉了遍历文件描述符的操作，而是采用监听事件回调机制。
##### IO模型之信号驱动模型
信号驱动IO不再用注定询问的方式去确认数据是否就绪，而是向内核发送一个信号（调用sigaction时候建一个sigio信号），然后应用用户进程可以做别的事，不用阻塞。当内核数据准备好了再通过sigio信号通知应用进程，数据准备好后的可读状态。应用用户进程收到信号之后立即调用recvfrom，去读取数据。
##### IO模型之异步(AIO)
AIO实现了IO全流程的非阻塞，就是应用进程发出系统调用后，是立即返回的，但是立即返回的不是处理结果，而是表示提交成功。等内核数据准备好，将数据拷贝到用户进程缓冲区，发送信号通知用户进程IO操作执行完毕。
#### 事务隔离级别
为了解决并发事务存在的脏读、不可重复读、幻读等问题，数据库设计了四种隔离级别。分别是读未提交、读已提交、可重复读、串行化（serializable）。
* 读未提交：只限制了两个数据不能同时修改，但是修改数据的时候，即使事务未提交，都是可以被别的事务读取到的，这个级别的事务隔离有脏读、重复读、幻读的问题。
* 读已提交：当前事务只能读取到其他事务提交的数据，所以此隔离级别解决了脏读的问题，但还是会存在重复读和幻读；
* 可重复读：限制了读取数据的时候不可以修改，解决了重复读的问题，但是读取范围数据的时候，是可以插入数据的，还会存在幻读问题；
* 串行化：事务最高的隔离级别，所有事务都是进行串行化顺序执行的。避免了脏读、不可重复读与幻读所有并发问题。但是此级别事务很耗性能。
> 脏读：事务1第二次读取的时候读到了事务2未提交的数据，若事务2回滚，则事务1读到的就是脏数据；  
> 不可重复读：事务1前后两次读取的数据因为事务2的提交产生了不一致；  
> 幻读：事务1对数据进行范围级别的修改，同时事务2插入一条新数据，此时事务1在读取数据会产生幻觉，多出未修改的数据行。
##### read view可见性规则
* m_ids：当前系统中那些活跃（未提交）的读写事务ID，数据结构为1个list；
* max_limit_id：表示生成read view时系统应该分配给下一个事务的id值；
* min_limit_id：表示在生成read view时当前系统活跃的读写事务中最小的事务id，即m_ids中的最小值；
* creator_trx_id：创建当前read view的事务ID。

可见性规则如下：
1. 如果数据事务ID trx_id < min_limit_id，表明生成该版本的事务在生成read view前，已经提交（因为事务ID是递增的），所以该版本可以被当前事务访问；
2. 如果trx_id >= max_limit_id，表明生成该版本的事务在生成read view后才生成，所以该版本不可以被当前事务访问；
3. 如果min_limit_id =<trx_id< max_limit_id， 1）如果 m_ids 包含 trx_id,则代表 Read View 生成时刻，这个事务还未提交，但是如果数据的 trx_id 等于 creator_trx_id 的话，表明数据是自己生成的，因此是可见的。 2）如果 m_ids 包含 trx_id，并且 trx_id 不等于 creator_trx_id，则Read View 生成时，事务未提交，并且不是自己生产的，所以当前事务也是看不见的；  3）如果 m_ids 不包含 trx_id，则说明你这个事务在 Read View 生成之前就已经提交了，修改的结果，当前事务是能看见的。
##### 可重复读实现原理
数据库是通过加锁实现隔离级别的，串行化隔离级别就是加锁实现，但是如果加锁频繁，性能会下降。所以出现了MVCC。  
MVCC，可重复读的实现原理就是MVCC多版本并发控制。在一个事务范围内，两个相同的查询，读取同一条记录，却返回了不同的数据，这就是不可重复读。可重复读隔离级别，就是为了解决不可重复读问题。  
查询一条记录，MVCC的流程：
1. 获取事务自己的版本号，即事务ID；
2. 获取read view；
3. 查询得到的数据，然后read view中的事务版本号进行比较；
4. 如果不符合read view可见性规则，即就需要undo log中历史快照；
5. 最后返回符合规则的数据。

Innodb实现MVCC是通过 Read View+ Undo Log 实现的，undo log保存了历史快照，read view可见性规则帮助判断当前版本的数据是否可见。
#### 虚拟内存
虚拟内存，是虚拟出来的内存，核心思想是确保每个程序拥有自己的地址空间，地址空间被分为多个块，每一个块都有连续的地址空间。同时物理空间也分为多个块，块大小和虚拟地址空间的块大小一致，操作系统会自动将虚拟地址空间映射到物理地址空间，程序只关心虚拟内存，请求的也是虚拟内存，真正使用的却是物理内存。  
现代操作系统使用虚拟内存，即虚拟地址取代物理地址，使用虚拟内存可以：
* 虚拟内存空间远远大于物理内存空间；
* 多个虚拟内存可以指向同一个物理地址。

零拷贝实现思想就利用了虚拟内存该特点：多个虚拟内存可以指向同一个物理地址，可以把内核空间和用户空间的虚拟地址映射到同一个物理地址，以此减少IO的数据拷贝次数。
#### 计算机网络体系结构
OSI七层协议、TCP/IP四层协议、五层协议
##### 应用层
应用层的任务是通过应用进程间的交互来完成特定网络应用。应用层协议定义的是应用进程间的通信和交互规则。对于不同的网络应用需要不同的应用层协议。如域名DNS、HTTP协议、SMTP协议等。
##### 运输层
运输层的主要任务是负责向两台主机进程之间的通信提供通用的数据传输服务。应用进程通过该服务传送应用层报文。运输层主要使用传输控制协议TCP和用户数据协议UDP。
##### 网络层
在计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换结点，确保数据及时传送。在发送数据时网络层把运输层产生的报文段或用户数据包封装成分组和包进行传送。在TCP/IP体系结构中，分组也叫IP数据报。
##### 数据链路层
通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层协议。两个相邻节点之间传送数据，数据链路层将网络层交下来的IP数据报组装成帧，在链路上传送帧。
##### 物理层
在物理层上所传送的数据单位是比特。物理层的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。
#### TCP三次握手
为了准确无误把数据送达目标处，TCP采用三次握手。三次握手的目的是建立可靠的通信通道，说到通讯，简单来说就是数据的发送与接受，而三次握手就是双方确认自己与对方的发送与接收都是正常的。
* 客户端-发送带有SYN标志的数据包进行第一次握手-服务端；（客户端什么都不能确认，服务端确认了对方发送正常，自己接收正常）
* 服务端-发送带有SYN/ACK标志的数据包进行二次握手-客户端；（客户端确认了自己接收正常、发送正常，对方发送接收正常；服务端确认对方发送正常，自己接收正常）
* 客户端-发送带有ACK标志的数据包进行第三次握手-服务端。（客户端确认了自己发送、接收正常，对方发送接收正常；服务端确认了自己发送、接收正常，对方发送接收正常 ）
#### 四次挥手
* 客户端发送一个FIN，用来关闭客户端到服务器的数据传送；
* 服务器收到FIN，它发回一个ACK，确认序号为收到的序号+1。和SYN一样，一个FIN将占用一个序号。
* 服务器关闭与客户端的连接，发送一个FIN给客户端。
* 客户端发回ACK报文确认，并将确认序号设置为收到序号+1。
#### TCP/UDP协议区别
* TCP：是面向连接的可靠的字节流传输，传输效率比较慢，需要的资源比较多，一般用于文件传输、邮件传输等。首部为20-60字节；
* UDP：是无连接的不可靠的数据报文的传输，传输效率比较快，需要的资源比较少，一般用于域名连接等。首部8个字节。
##### TCP协议如何保证可靠传输
* 应用数据被分割成TCP认为最适合发送的数据块；
* TCP给发送的每一个数据包进行编号，接收方对数据包进行排序，把有序数据传送给应用层；
* 校验和：TCP将保持它首部和数据的校验和。这是一个端到端的校验和，目的是检测数据在传输过程中的任何变化。如果收到段的校验和有差错，TCP将丢弃这个报文段和不确认收到此报文段；
* TCP的接收端会丢弃重复的数据；
* 流量控制：TCP连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送发的数据，能提示发送方降低发送的速率，防止丢包。TCP使用的流量控制协议是可变大小的滑动窗口协议。（TCP利用滑动窗口实现流量控制）
* 拥塞控制：当网络拥塞时，减少数据的发送；
* AQR协议：为了实现可靠传输的协议，基本原理是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。
* 超时重传：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。
#### 浏览器输入url地址打开网页的过程
1. 浏览器查找域名的IP地址（DNS查找过程：浏览器缓存、路由缓存、DNS缓存）；
2. 浏览器向一个web服务器发送一个HTTP请求（cookie会随着请求发送个服务器）；
3. 服务器处理请求（处理请求、参数、cookie生成一个HTML响应）；
4. 服务器返回一个HTML响应；
5. 浏览器显示HTML。
#### cookie和session
* cookie一般用来保存用户信息。如保存已登录过的用户信息，下次访问网站的时候页面可以自动填写一些登录的信息；或是保持登录的场景，是因为cookie中保存了一个token。cookie数据保存在客户端（浏览器端），不够安全。
* session主要作用是通过服务端记录用户的状态。典型场景是购物车。session数据保存在服务器端，安全性更高。
#### URI和URL
* URI是统一资源标志符，可以唯一标识一个资源；
* URL是统一资源定位符，可以提供该资源的路径。它是一种具体的URI。

### Spring
#### Spring MVC工作原理
1. 客户端（浏览器）发送请求，直接请求到DispatcherServlet（前端控制器）；
2. DispatcherServlet根据请求信息调用HandlerMapping（处理器映射器），解析请求对应的Handler；
3. 解析到对应的Handler（即controller）后开始由HandlerAdapter适配器处理；
4. HandlerAdapter会根据handler来调用真正的处理器处理请求，并处理相应的业务逻辑；
5. 处理器处理完业务后，会返回一个ModelAndView对象，Model是返回的数据对象，View是逻辑上的view；
6. ViewResolver视图解析器会根据逻辑view找到实际view；
7. DispatcherServlet把返回的model传给View进行视图渲染；
8. 最后把view返回给客户端。
* DispatcherServlet 前端控制器：接受请求，进行分发，并根据视图解析器进行响应渲染；
* HandlerMapping 处理器映射器：包含请求路径和模型的对应关系，能够完成请求到controller映射；
* Controller/Handler 处理器：处理业务逻辑，
* ViewResovler 视图解析器：进行视图解析，前端控制器依据ViewResovler的解析调用真正的视图对象生成相应页面。




### SpringCloud
#### Gateway
自动配置类：GatewayAutoConfiguration，Spring Cloud Gateway的创建比较复杂，核心类就是GatewayAutoConfiguration，主要实现以下功能：
* 配置了Netty；
* 创建了GatewayProperties，这里从属性文件中获取了路由器配置和默认过滤器配置；
* 创建了属性RouteDefinitionLocator，内存RouteDefinitionLocator和自动发现服务RouteDefinitionLocator, 并且将这三者合并为CompositeRouteDefinitionLocator；
* 使用GatewayProperties+所有的GatewayFilterFactory,RoutePredicateFactory+CompositeRouteDefinitionLocator创建路由器列表RouteLocator, 这个东西包含所有；
* 创建了一批全局过滤器；
* 创建过滤器处理类 FilteringWebHandler；
* 创建请求处理类 RoutePredicateHandlerMapping。
> 客户端向Spring Cloud Gateway发出请求，然后在Gateway Handler Mapping中找到与请求相匹配的路由，将其发送到Gateway Web Handler。Handler再通过指定的过滤器链将请求发送到实际的服务执行业务逻辑，然后返回。过滤器可能会在发送代理请求之前（pre）或之后（post）执行业务逻辑。

#### Gateway filter
在配置文件中的filters中填写前缀即可，最终通过gatewayFilterFactories容器，key是factory.name()，而 value 是对应的 GatewayFilterFactory类型实现。  
filter order：最终都是通过Order值进行排序执行，Order值越小越先执行。  
GlobalFilter：全局过滤器，对所有路由生效。通过实现GlobalFilter接口创建。  
GatewayFilter：网关过滤器，也可以说是局部过滤器、自定义过滤器，只对配置了此过滤器的路由生效。通过GatewayFilterFactory创建。
过滤器会被执行两次，过滤分为pre和post。  
pre：请求前调用。
post：响应结果返回时调用，顺序和pre完全相反，这里只讨论过滤器的pre执行顺序，post倒置过来就行了。  
1. 两个GlobalFilter类型的过滤器Order值相同时，根据文件名字母排序，文件名靠前的优先更高。原因是包扫描时是按照文件的顺序扫描的，然后封装到List集合的，通过Order值排序时如果Order值相同，文件名在前名的依然会排在前面。
2. GlobalFilter类型和GatewayFilter类型的过滤器Order值相同时，GlobalFilter类型优先更高。原因是这两种过滤器最终会合并到一个过滤器集合中形成过滤器调用链，源码是通过list.addAll();方法将GatewayFilter类型的过滤器加到了GlobalFilter过滤器集合中，addAll()是末尾添加方式，所以Order值相同时GatewayFilter类型的过滤器会排在后面。



### HTTP服务调用
REST Template和Feign Client
* REST Template：通过Ribbon(负载均衡)和RestTemplate是实现；
* Feign Client：OpenFeign(Spring Cloud OpenFeign)，用以替代Feign（Netflix Feign）
#### 常用注解
OpenFeign 声明式服务调用和负载均衡组件，因此核心是使用注解+接口的方式实现服务调用。对于Feign框架来说，只支持Feign注解和JAX-RS注解，OpenFeign在其基础上增加了对Spring MVC注解的支持。
* @EnableFeignClients：用于开启OpenFeign功能，当应用启动时，OpenFeign会扫描有@FeignClient注解的接口，生成代理并注册到Spring容器中；
* @FeignClient：用于通知OpenFeign组件对@RequestMapping注解下接口进行解析，并通过动态代理的方式产生实现类，实现负载均衡和服务调用。
